{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_flag\n",
    "#hide\n",
    "from medtop.core import *\n",
    "from medtop.helpers import *\n",
    "from medtop.nlp_helpers import *\n",
    "from medtop.preprocessing import *\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "# wide screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CI](https://github.com/cctrbic/medtop/workflows/CI/badge.svg)\n",
    "# MedTop\n",
    "\n",
    "> Extracting topics from reflective medical writings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install medtop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NLTK data to your machine using `python -m nltk.downloader all`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import documents from a text file containing a list of all documents  \n",
    "**QUESTION: I can't see anywhere we are actually using `my_docs_pos` or `my_docs_loc`. Can we remove these?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: some documents aren't loading properly\n",
    "path_to_file_list = 'data/2019.03.11_DevCorpus/file_list.txt'\n",
    "data, doc_df = import_docs(path_to_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review the imported documents manually by writing the raw sentences to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_disk(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the TF-IDF matrix. `path_to_corpus_file_list` can be a list of just input files (Local) or a list of all files in the corpus (Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TF-IDF: 14 Docs, 860 Tokens\n"
     ]
    }
   ],
   "source": [
    "path_to_seed_topics_file_list = 'data/2019.03.12_SEED_TOPICS/FILELIST.txt'\n",
    "tfidf, dictionary = create_tfidf(path_to_seed_topics_file_list, doc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the most expressive phrase from each sentence.  \n",
    "\n",
    "**Need a better understanding of `include_input_in_tfidf` and `token_averages = get_term_max(tdm)`. They don't seem to be representative of their names.**  \n",
    "\n",
    "**Also, I think this is sloppy how I'm appending a column in place. Probably want to refactor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_sent_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc.0.sent.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I am currently on my first AI in the Emergency...</td>\n",
       "      <td>[currently, emergency, department]</td>\n",
       "      <td>[[currently, RB], [Emergency, NNP], [Departmen...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc.0.sent.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I completely agree with what others have said ...</td>\n",
       "      <td>[completely, agree, others, said, previous, po...</td>\n",
       "      <td>[[completely, RB], [agree, VBP], [others, NNS]...</td>\n",
       "      <td>[confident, clerkship, suddenly, feeling, over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc.0.sent.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>For example, learning how to place orders in t...</td>\n",
       "      <td>[example, learning, place, order, using, emr, ...</td>\n",
       "      <td>[[example, NN], [learning, VBG], [place, VB], ...</td>\n",
       "      <td>[learning, place, order, using, emr, different]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc.0.sent.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Signing up for patients requires me to first c...</td>\n",
       "      <td>[signing, requires, check, provider]</td>\n",
       "      <td>[[Signing, VBG], [requires, VBZ], [check, VB],...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc.0.sent.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>At the same time, the patients are sick and I ...</td>\n",
       "      <td>[time, sick, responsibility, come, plan, prese...</td>\n",
       "      <td>[[time, NN], [sick, JJ], [responsibility, NN],...</td>\n",
       "      <td>[sick, responsibility, come, plan, present, at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>doc.8.sent.11</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>It was challenging to see living conditions in...</td>\n",
       "      <td>[challenging, see, living, condition, poorer, ...</td>\n",
       "      <td>[[challenging, VBG], [see, VB], [living, JJ], ...</td>\n",
       "      <td>[challenging, see, living, condition, poorer, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>doc.8.sent.12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>We as Drs.</td>\n",
       "      <td>[drs]</td>\n",
       "      <td>[[Drs, NNP]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>doc.8.sent.13</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>are tasked with treating people who will leave...</td>\n",
       "      <td>[tasked, treating, people, leave, care, reente...</td>\n",
       "      <td>[[tasked, VBN], [treating, VBG], [people, NNS]...</td>\n",
       "      <td>[room, crispt, clean, sheet, always, waiting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>doc.8.sent.14</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>I felt my EMT ride along was a great way to st...</td>\n",
       "      <td>[felt, emt, ride, along, great, start, rotatio...</td>\n",
       "      <td>[[felt, VBD], [EMT, NNP], [ride, NN], [along, ...</td>\n",
       "      <td>[felt, emt, ride, along, great, start]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>doc.9.sent.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>I am currently completing my ICU AI requiremen...</td>\n",
       "      <td>[currently, completing, icu, requirement, picu...</td>\n",
       "      <td>[[currently, RB], [completing, VBG], [ICU, NNP...</td>\n",
       "      <td>[best, asset, teamâ, however, think, challenging]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_sent_id doc_id sent_id  \\\n",
       "0     doc.0.sent.0      0       0   \n",
       "1     doc.0.sent.1      0       1   \n",
       "2     doc.0.sent.2      0       2   \n",
       "3     doc.0.sent.3      0       3   \n",
       "4     doc.0.sent.4      0       4   \n",
       "..             ...    ...     ...   \n",
       "111  doc.8.sent.11      8      11   \n",
       "112  doc.8.sent.12      8      12   \n",
       "113  doc.8.sent.13      8      13   \n",
       "114  doc.8.sent.14      8      14   \n",
       "115   doc.9.sent.0      9       0   \n",
       "\n",
       "                                                  text  \\\n",
       "0    I am currently on my first AI in the Emergency...   \n",
       "1    I completely agree with what others have said ...   \n",
       "2    For example, learning how to place orders in t...   \n",
       "3    Signing up for patients requires me to first c...   \n",
       "4    At the same time, the patients are sick and I ...   \n",
       "..                                                 ...   \n",
       "111  It was challenging to see living conditions in...   \n",
       "112                                         We as Drs.   \n",
       "113  are tasked with treating people who will leave...   \n",
       "114  I felt my EMT ride along was a great way to st...   \n",
       "115  I am currently completing my ICU AI requiremen...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0                   [currently, emergency, department]   \n",
       "1    [completely, agree, others, said, previous, po...   \n",
       "2    [example, learning, place, order, using, emr, ...   \n",
       "3                 [signing, requires, check, provider]   \n",
       "4    [time, sick, responsibility, come, plan, prese...   \n",
       "..                                                 ...   \n",
       "111  [challenging, see, living, condition, poorer, ...   \n",
       "112                                              [drs]   \n",
       "113  [tasked, treating, people, leave, care, reente...   \n",
       "114  [felt, emt, ride, along, great, start, rotatio...   \n",
       "115  [currently, completing, icu, requirement, picu...   \n",
       "\n",
       "                                              pos_tags  \\\n",
       "0    [[currently, RB], [Emergency, NNP], [Departmen...   \n",
       "1    [[completely, RB], [agree, VBP], [others, NNS]...   \n",
       "2    [[example, NN], [learning, VBG], [place, VB], ...   \n",
       "3    [[Signing, VBG], [requires, VBZ], [check, VB],...   \n",
       "4    [[time, NN], [sick, JJ], [responsibility, NN],...   \n",
       "..                                                 ...   \n",
       "111  [[challenging, VBG], [see, VB], [living, JJ], ...   \n",
       "112                                       [[Drs, NNP]]   \n",
       "113  [[tasked, VBN], [treating, VBG], [people, NNS]...   \n",
       "114  [[felt, VBD], [EMT, NNP], [ride, NN], [along, ...   \n",
       "115  [[currently, RB], [completing, VBG], [ICU, NNP...   \n",
       "\n",
       "                                                phrase  \n",
       "0                                                 None  \n",
       "1    [confident, clerkship, suddenly, feeling, over...  \n",
       "2      [learning, place, order, using, emr, different]  \n",
       "3                                                 None  \n",
       "4    [sick, responsibility, come, plan, present, at...  \n",
       "..                                                 ...  \n",
       "111  [challenging, see, living, condition, poorer, ...  \n",
       "112                                               None  \n",
       "113      [room, crispt, clean, sheet, always, waiting]  \n",
       "114             [felt, emt, ride, along, great, start]  \n",
       "115  [best, asset, teamâ, however, think, challenging]  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = append_phrase_column(data, dictionary.token2id, tfidf, include_input_in_tfidf = False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sentence vectors\n",
    "**TODO: add explanations**\n",
    "- TF-IDF\n",
    "- SVD\n",
    "- UMAP\n",
    "- Pre-trained Word2Vec embeddings\n",
    "- Create Word2Vec embeddings from input corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_sent_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>phrase</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc.0.sent.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I am currently on my first AI in the Emergency...</td>\n",
       "      <td>[currently, emergency, department]</td>\n",
       "      <td>[[currently, RB], [Emergency, NNP], [Departmen...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc.0.sent.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I completely agree with what others have said ...</td>\n",
       "      <td>[completely, agree, others, said, previous, po...</td>\n",
       "      <td>[[completely, RB], [agree, VBP], [others, NNS]...</td>\n",
       "      <td>[confident, clerkship, suddenly, feeling, over...</td>\n",
       "      <td>[0.20960833, 0.7227674, 0.105357334, 0.1128086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc.0.sent.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>For example, learning how to place orders in t...</td>\n",
       "      <td>[example, learning, place, order, using, emr, ...</td>\n",
       "      <td>[[example, NN], [learning, VBG], [place, VB], ...</td>\n",
       "      <td>[learning, place, order, using, emr, different]</td>\n",
       "      <td>[0.15176998, 0.0, 0.08150944, 0.44046646, 0.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc.0.sent.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Signing up for patients requires me to first c...</td>\n",
       "      <td>[signing, requires, check, provider]</td>\n",
       "      <td>[[Signing, VBG], [requires, VBZ], [check, VB],...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc.0.sent.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>At the same time, the patients are sick and I ...</td>\n",
       "      <td>[time, sick, responsibility, come, plan, prese...</td>\n",
       "      <td>[[time, NN], [sick, JJ], [responsibility, NN],...</td>\n",
       "      <td>[sick, responsibility, come, plan, present, at...</td>\n",
       "      <td>[0.11805223, 0.07557625, 0.27154884, 0.0555973...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>doc.8.sent.11</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>It was challenging to see living conditions in...</td>\n",
       "      <td>[challenging, see, living, condition, poorer, ...</td>\n",
       "      <td>[[challenging, VBG], [see, VB], [living, JJ], ...</td>\n",
       "      <td>[challenging, see, living, condition, poorer, ...</td>\n",
       "      <td>[0.0, 0.0, 0.035119113, 0.037602875, 0.0, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>doc.8.sent.12</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>We as Drs.</td>\n",
       "      <td>[drs]</td>\n",
       "      <td>[[Drs, NNP]]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>doc.8.sent.13</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>are tasked with treating people who will leave...</td>\n",
       "      <td>[tasked, treating, people, leave, care, reente...</td>\n",
       "      <td>[[tasked, VBN], [treating, VBG], [people, NNS]...</td>\n",
       "      <td>[room, crispt, clean, sheet, always, waiting]</td>\n",
       "      <td>[0.0, 0.09546891, 0.063848935, 0.13672917, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>doc.8.sent.14</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>I felt my EMT ride along was a great way to st...</td>\n",
       "      <td>[felt, emt, ride, along, great, start, rotatio...</td>\n",
       "      <td>[[felt, VBD], [EMT, NNP], [ride, NN], [along, ...</td>\n",
       "      <td>[felt, emt, ride, along, great, start]</td>\n",
       "      <td>[0.08989336, 0.0, 0.02872982, 0.2898388, 0.086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>doc.9.sent.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>I am currently completing my ICU AI requiremen...</td>\n",
       "      <td>[currently, completing, icu, requirement, picu...</td>\n",
       "      <td>[[currently, RB], [completing, VBG], [ICU, NNP...</td>\n",
       "      <td>[best, asset, teamâ, however, think, challenging]</td>\n",
       "      <td>[0.0, 0.0, 0.035119113, 0.08329714, 0.0, 0.044...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_sent_id doc_id sent_id  \\\n",
       "0     doc.0.sent.0      0       0   \n",
       "1     doc.0.sent.1      0       1   \n",
       "2     doc.0.sent.2      0       2   \n",
       "3     doc.0.sent.3      0       3   \n",
       "4     doc.0.sent.4      0       4   \n",
       "..             ...    ...     ...   \n",
       "111  doc.8.sent.11      8      11   \n",
       "112  doc.8.sent.12      8      12   \n",
       "113  doc.8.sent.13      8      13   \n",
       "114  doc.8.sent.14      8      14   \n",
       "115   doc.9.sent.0      9       0   \n",
       "\n",
       "                                                  text  \\\n",
       "0    I am currently on my first AI in the Emergency...   \n",
       "1    I completely agree with what others have said ...   \n",
       "2    For example, learning how to place orders in t...   \n",
       "3    Signing up for patients requires me to first c...   \n",
       "4    At the same time, the patients are sick and I ...   \n",
       "..                                                 ...   \n",
       "111  It was challenging to see living conditions in...   \n",
       "112                                         We as Drs.   \n",
       "113  are tasked with treating people who will leave...   \n",
       "114  I felt my EMT ride along was a great way to st...   \n",
       "115  I am currently completing my ICU AI requiremen...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0                   [currently, emergency, department]   \n",
       "1    [completely, agree, others, said, previous, po...   \n",
       "2    [example, learning, place, order, using, emr, ...   \n",
       "3                 [signing, requires, check, provider]   \n",
       "4    [time, sick, responsibility, come, plan, prese...   \n",
       "..                                                 ...   \n",
       "111  [challenging, see, living, condition, poorer, ...   \n",
       "112                                              [drs]   \n",
       "113  [tasked, treating, people, leave, care, reente...   \n",
       "114  [felt, emt, ride, along, great, start, rotatio...   \n",
       "115  [currently, completing, icu, requirement, picu...   \n",
       "\n",
       "                                              pos_tags  \\\n",
       "0    [[currently, RB], [Emergency, NNP], [Departmen...   \n",
       "1    [[completely, RB], [agree, VBP], [others, NNS]...   \n",
       "2    [[example, NN], [learning, VBG], [place, VB], ...   \n",
       "3    [[Signing, VBG], [requires, VBZ], [check, VB],...   \n",
       "4    [[time, NN], [sick, JJ], [responsibility, NN],...   \n",
       "..                                                 ...   \n",
       "111  [[challenging, VBG], [see, VB], [living, JJ], ...   \n",
       "112                                       [[Drs, NNP]]   \n",
       "113  [[tasked, VBN], [treating, VBG], [people, NNS]...   \n",
       "114  [[felt, VBD], [EMT, NNP], [ride, NN], [along, ...   \n",
       "115  [[currently, RB], [completing, VBG], [ICU, NNP...   \n",
       "\n",
       "                                                phrase  \\\n",
       "0                                                 None   \n",
       "1    [confident, clerkship, suddenly, feeling, over...   \n",
       "2      [learning, place, order, using, emr, different]   \n",
       "3                                                 None   \n",
       "4    [sick, responsibility, come, plan, present, at...   \n",
       "..                                                 ...   \n",
       "111  [challenging, see, living, condition, poorer, ...   \n",
       "112                                               None   \n",
       "113      [room, crispt, clean, sheet, always, waiting]   \n",
       "114             [felt, emt, ride, along, great, start]   \n",
       "115  [best, asset, teamâ, however, think, challenging]   \n",
       "\n",
       "                                                   vec  \n",
       "0                                                 None  \n",
       "1    [0.20960833, 0.7227674, 0.105357334, 0.1128086...  \n",
       "2    [0.15176998, 0.0, 0.08150944, 0.44046646, 0.39...  \n",
       "3                                                 None  \n",
       "4    [0.11805223, 0.07557625, 0.27154884, 0.0555973...  \n",
       "..                                                 ...  \n",
       "111  [0.0, 0.0, 0.035119113, 0.037602875, 0.0, 0.04...  \n",
       "112                                               None  \n",
       "113  [0.0, 0.09546891, 0.063848935, 0.13672917, 0.0...  \n",
       "114  [0.08989336, 0.0, 0.02872982, 0.2898388, 0.086...  \n",
       "115  [0.0, 0.0, 0.035119113, 0.08329714, 0.0, 0.044...  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = append_vec_column(\"tfidf\", data, dictionary = dictionary, tfidf = tfidf)\n",
    "# data = append_vec_column(\"svd\", data, dictionary = dictionary, tfidf = tfidf)\n",
    "# data = append_vec_column(\"umap\", data, dictionary = dictionary, tfidf = tfidf)\n",
    "# data = append_vec_column(\"pretrained\", data, path_to_w2v_bin_file = \"data/pubmed2018_w2v_200D.bin\")\n",
    "# data = append_vec_column(\"local\", data, doc_df = doc_df)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the sentences, removing any that contain zero \"top phrases\"  \n",
    "**QUESTION: After filtering here, we never again use the filtered records in my_docs, could we filter in place to make this cleaner?**  \n",
    "**QUESTION: Is there a reason we're storing `just_phrase_ids` as a concatenated string instead of a tuple? We can always convert to string when writing to a file, but it makes for messier logic than necessary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_phrase_num = sum([len(phrase_vecs) for phrase_vecs in doc_phrase_vecs])\n",
    "# just_phrase_vecs, just_phrase_ids, just_phrase_text = filter_sentences(doc_phrase_vecs, doc_top_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "**QUESTION: Is there still a need to save charts?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means Clustering\n",
    "When using K-means clustering, you can find the optimal k value from a given range. `get_optimal_k` visualizes the silhoute coefficients for a range of k values and returns the value corresponding to the max silhoute coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_k = get_optimal_k(just_phrase_vecs, save_chart = False)\n",
    "# cluster_assignments, dist = get_cluster_assignments_kmeans(optimal_k, just_phrase_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Agglomerative Clustering\n",
    "When using Hierarchical Agglomerative Clustering, you can find the optimal height value from a given range. `get_optimal_height` visualizes the silhoute coefficients for a range of heights and returns the value corresponding to the max silhoute coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkage_matrix = get_linkage_matrix(just_phrase_vecs, \"euclidean\")\n",
    "# optimal_height = get_optimal_height(just_phrase_vecs, linkage_matrix, save_chart = False)\n",
    "# cluster_assignments = get_cluster_assignments_hac(linkage_matrix, optimal_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "All visualization uses cosine similarity. **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from gensim import corpora, models, similarities\n",
    "import matplotlib.pyplot as plt\n",
    "from medtop.nlp_helpers import *\n",
    "from medtop.preprocessing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from scipy.cluster.hierarchy import ward, cut_tree\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = pairwise_distances(just_phrase_vecs, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION: Should visualization be three separate methods or a single method with optional parameters? There are a few other similar instances in the code where we could do multiple top-level methods or a single caller with kwargs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: This is not displaying correctly in the README\n",
    "# visualize_umap(just_phrase_ids, cluster_assignments, just_phrase_text, dist)\n",
    "# # visualize_mds(just_phrase_ids, cluster_assignments, just_phrase_text, dist)\n",
    "# # visualize_svd(just_phrase_ids, cluster_assignments, just_phrase_text, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION: The variables here are named `cluster_topics`, but it seems like they're actual lists of phrases in each cluster. Need clarification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cluster_topics = get_cluster_topics(cluster_assignments, just_phrase_ids, my_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_output_to_disk(main_cluster_topics, just_phrase_ids, cluster_assignments, raw_sentences, doc_top_phrases, file_list, file_name = \"output/TopicClusterResults.txt\")\n",
    "# evaluate(just_phrase_ids, cluster_assignments, just_phrase_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Core.ipynb.\n",
      "Converted helpers.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted nlp_helpers.ipynb.\n",
      "Converted preprocessing.ipynb.\n",
      "Converted Sandbox.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
