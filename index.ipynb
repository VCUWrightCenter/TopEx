{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedTop\n",
    "\n",
    "> Extracting topics from reflective medical writings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "`pip install medtop`  \n",
    "\n",
    "`python -m nltk.downloader all`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A template pipeline is provided below using a test dataset. You can read more about the test_data dataset [here](https://github.com/cctrbic/medtop/blob/master/test_data/README.md)\n",
    "\n",
    "Each step of the pipeline has configuration options for experimenting with various methods. These are detailed in the documentation for each method. Notably, the `import_docs`, `get_cluster_topics`, `visualize_clustering`, and `evaluate` methods all include the option to save results to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Pipeline\n",
    "### Import data\n",
    "Import and pre-process documents from a text file containing a list of all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medtop.core import *\n",
    "data, doc_df = import_docs('test_data/corpus_file_list.txt', save_results = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data\n",
    "Create word vectors from the most expressive phrase in each sentence of the imported documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 43 sentences without phrases.\n"
     ]
    }
   ],
   "source": [
    "tfidf, dictionary = create_tfidf('test_data/seed_topics_file_list.txt', doc_df)\n",
    "data = get_phrases(data, dictionary.token2id, tfidf, include_input_in_tfidf = True)\n",
    "data = get_vectors(\"tfidf\", data, dictionary = dictionary, tfidf = tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions about unrepresentative names:**   \n",
    "  1) Need a better understanding of `include_input_in_tfidf`  \n",
    "  2) Why is `token_averages` is the max of each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster data\n",
    "Cluster the sentences into groups expressing similar ideas or topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>topics</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[felt, guilt, lost, joy, lied, going, work, sa...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[felt, guilt, joy, shame, christmas, friend, n...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[felt, joy, got, found, shame, guilt, son, for...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[felt, sadness, died, friend, dog, heard, joy,...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                             topics  sent_count\n",
       "0        0  [felt, guilt, lost, joy, lied, going, work, sa...          14\n",
       "1        1  [felt, guilt, joy, shame, christmas, friend, n...          75\n",
       "2        2  [felt, joy, got, found, shame, guilt, son, for...          25\n",
       "3        3  [felt, sadness, died, friend, dog, heard, joy,...          40"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = assign_clusters(data, method = \"kmeans\", k=4)\n",
    "cluster_df = get_cluster_topics(data, doc_df, save_results = False)\n",
    "visualize_clustering(data, method = \"umap\", show_chart = False)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>gold_examples</th>\n",
       "      <th>closest_cluster</th>\n",
       "      <th>closest_cluster_members</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guilt</td>\n",
       "      <td>{doc.2.sent.8, doc.2.sent.6, doc.6.sent.18, do...</td>\n",
       "      <td>1</td>\n",
       "      <td>{doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>{doc.4.sent.3, doc.5.sent.3, doc.6.sent.12, do...</td>\n",
       "      <td>1</td>\n",
       "      <td>{doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>{doc.3.sent.7, doc.0.sent.17, doc.8.sent.4, do...</td>\n",
       "      <td>3</td>\n",
       "      <td>{doc.3.sent.7, doc.0.sent.17, doc.8.sent.4, do...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shame</td>\n",
       "      <td>{doc.3.sent.4, doc.6.sent.10, doc.3.sent.1, do...</td>\n",
       "      <td>1</td>\n",
       "      <td>{doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...</td>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                      gold_examples  \\\n",
       "1    guilt  {doc.2.sent.8, doc.2.sent.6, doc.6.sent.18, do...   \n",
       "2      joy  {doc.4.sent.3, doc.5.sent.3, doc.6.sent.12, do...   \n",
       "0  sadness  {doc.3.sent.7, doc.0.sent.17, doc.8.sent.4, do...   \n",
       "3    shame  {doc.3.sent.4, doc.6.sent.10, doc.3.sent.1, do...   \n",
       "\n",
       "   closest_cluster                            closest_cluster_members  tp  fp  \\\n",
       "1                1  {doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...  32  43   \n",
       "2                1  {doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...  25  50   \n",
       "0                3  {doc.3.sent.7, doc.0.sent.17, doc.8.sent.4, do...  27  13   \n",
       "3                1  {doc.2.sent.8, doc.2.sent.6, doc.4.sent.3, doc...  18  57   \n",
       "\n",
       "   fn  precision  recall     f1  \n",
       "1  36      0.427   0.471  0.448  \n",
       "2  38      0.333   0.397  0.362  \n",
       "0  11      0.675   0.711  0.693  \n",
       "3  13      0.240   0.581  0.340  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_file = \"test_data/gold.txt\"\n",
    "evaluate(data, gold_file=\"test_data/gold.txt\", save_results = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted core.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted internal.ipynb.\n",
      "Converted preprocessing.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
